<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tutorial: Sistema de Reconocimiento Facial con Python</title>
    <style>
        body {
            font-family: 'Times New Roman', serif;
            line-height: 1.6;
            margin: 40px;
            background-color: #0d1117;
            color: #c9d1d9;
        }
        h1, h2, h3 {
            color: #f0f6fc;
            font-weight: normal;
        }
        code {
            background-color: #161b22;
            color: #f0f6fc;
            padding: 15px;
            border-radius: 6px;
            font-family: 'Courier New', monospace;
            display: block;
            white-space: pre-wrap;
            margin: 15px 0;
            border: 1px solid #21262d;
            box-sizing: border-box;
        }
        .section {
            background-color: #161b22;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            border: 1px solid #21262d;
        }
        .highlight {
            background-color: #0d4429;
            padding: 15px;
            border-left: 5px solid #238636;
            margin: 15px 0;
            color: #f0f6fc;
        }
        ul {
            margin-left: 20px;
        }
        .code-container {
            background-color: #161b22;
            color: #c9d1d9;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 14px;
            border: 1px solid #21262d;
        }
        footer {
            color: #8b949e;
        }
    </style>
</head>
<body>
    <h1>üñ•Ô∏è Tutorial: Sistema de Reconocimiento Facial con Python</h1>

    <div class="section">
        <h2>üìã Descripci√≥n del Sistema</h2>
        <p>Este tutorial explica c√≥mo utilizar el script <strong>1-reconocimento_facial.py</strong>, un sistema completo de reconocimiento facial desarrollado en Python que implementa dos algoritmos avanzados:</p>

        <ul>
            <li><strong>LBPH (Local Binary Pattern Histograms)</strong>: Algoritmo r√°pido y eficiente para datasets m√°s peque√±os</li>
            <li><strong>SVM con caracter√≠sticas HOG</strong>: Algoritmo m√°s preciso para datasets grandes con mayor precisi√≥n</li>
        </ul>

        <div class="highlight">
            <strong>Caracter√≠sticas principales:</strong>
            <ul>
                <li>‚òÜ Entrenamiento autom√°tico desde carpetas organizadas</li>
                <li>‚òÜ Reconocimiento en im√°genes est√°ticas y tiempo real con webcam</li>
                <li>‚òÜ Extracci√≥n autom√°tica de rostros reconocidos</li>
                <li>‚òÜ Par√°metros optimizados para reducir falsos positivos</li>
                <li>‚òÜ Redimensionamiento autom√°tico de im√°genes grandes</li>
                <li>‚òÜ Men√∫ interactivo f√°cil de usar</li>
            </ul>
        </div>
    </div>

    <div class="section">
        <h2>‚öôÔ∏è Requisitos Previos</h2>

        <h3>Instalaci√≥n de Dependencias</h3>
        <p>Antes de ejecutar el script, necesitas instalar las siguientes librer√≠as de Python:</p>

        <code>pip install opencv-python opencv-contrib-python scikit-learn numpy joblib</code>

        <h3>Estructura del Dataset</h3>
        <p>El sistema espera que las im√°genes de entrenamiento est√©n organizadas de la siguiente manera:</p>

        <code>
rostros_dataset/
‚îú‚îÄ‚îÄ Persona1/
‚îÇ   ‚îú‚îÄ‚îÄ foto1.jpg
‚îÇ   ‚îú‚îÄ‚îÄ foto2.jpg
‚îÇ   ‚îî‚îÄ‚îÄ foto3.jpg
‚îú‚îÄ‚îÄ Persona2/
‚îÇ   ‚îú‚îÄ‚îÄ foto1.jpg
‚îÇ   ‚îî‚îÄ‚îÄ foto2.jpg
‚îî‚îÄ‚îÄ PersonaN/
    ‚îú‚îÄ‚îÄ foto1.jpg
    ‚îî‚îÄ‚îÄ foto2.jpg
        </code>

        <div class="highlight">
            <strong>üí° Recomendaciones para un buen dataset:</strong>
            <ul>
                <li>Usa al menos 10-15 fotos por persona para mejores resultados</li>
                <li>Incluye fotos con diferentes √°ngulos, iluminaci√≥n y expresiones</li>
                <li>Formato preferido: JPG o PNG</li>
                <li>Resoluci√≥n m√≠nima: 100x100 p√≠xeles</li>
            </ul>
        </div>
    </div>

    <div class="section">
        <h2>üöÄ C√≥mo Usar el Sistema</h2>

        <h3>Paso 1: Ejecutar el Script</h3>
        <code>python 1-reconocimento_facial.py</code>

        <h3>Paso 2: Men√∫ Principal</h3>
        <p>Despu√©s de ejecutar el script, ver√°s el siguiente men√∫:</p>

        <code>
ü§ñ Sistema de Reconocimiento Facial
========================================
‚ú® MEJORADO: Par√°metros optimizados para reducir falsos positivos

Opciones:
1. Entrenar modelos
2. Reconocer rostros en imagen
3. Reconocimiento en tiempo real (webcam)
4. Configurar umbrales
5. Salir
        </code>

        <h3>Paso 3: Entrenar el Sistema (Opci√≥n 1)</h3>
        <p>Esta es la primera etapa. El sistema:</p>
        <ul>
            <li>Carga todas las im√°genes del dataset</li>
            <li>Extrae rostros autom√°ticamente usando el detector de cascada Haar</li>
            <li>Entrena ambos modelos (LBPH y SVM) simult√°neamente</li>
            <li>Guarda los modelos en archivos (modelo_lbph.yml, modelo_svm.pkl, etc.)</li>
        </ul>

        <h3>Paso 4: Reconocimiento en Im√°genes (Opci√≥n 2)</h3>
        <ul>
            <li>Ingresa la ruta completa de la imagen a analizar</li>
            <li>Selecciona el algoritmo (lbph o svm)</li>
            <li>El sistema marcar√° los rostros detectados con rect√°ngulos verdes</li>
            <li>Los rostros reconocidos se extraen autom√°ticamente a la carpeta <code>rostros_extraidos_inferidos/</code></li>
            <li>Se mostrar√° una ventana con el resultado y m√©tricas de confianza</li>
        </ul>

        <h3>Paso 5: Reconocimiento en Tiempo Real (Opci√≥n 3)</h3>
        <ul>
            <li>Requiere una webcam conectada</li>
            <li>Selecciona el algoritmo de reconocimiento</li>
            <li>Apunta la c√°mara a las personas a reconocer</li>
            <li>Presiona 'q' para salir</li>
            <li>Presiona 's' para guardar rostros manualmente</li>
            <li>Los rostros se guardan autom√°ticamente cada 30 segundos</li>
        </ul>

        <h3>Paso 6: Configurar Par√°metros (Opci√≥n 4)</h3>
        <p>Permite revisar los par√°metros actuales optimizados para reducir falsos positivos:</p>
        <ul>
            <li>Tama√±o m√≠nimo del rostro: 50 p√≠xeles</li>
            <li>Umbral de confianza LBPH: 80</li>
            <li>Umbral de probabilidad SVM: 0.6</li>
        </ul>
    </div>

    <div class="section">
        <h2>üìä Algoritmos Disponibles</h2>

        <h3>Local Binary Pattern Histograms (LBPH)</h3>
        <p>R√°pido y eficiente para datasets peque√±os. Funciona comparando texturas locales de los rostros.</p>

        <h3>SVM con Caracter√≠sticas HOG</h3>
        <p>M√°s preciso para datasets grandes. Combina descriptores HOG (Histogram of Oriented Gradients) con Support Vector Machines.</p>

        <div class="highlight">
            <strong>Cu√°ndo usar cada algoritmo:</strong>
            <ul>
                <li><strong>LBPH</strong>: Datasets peque√±os, velocidad prioritaria</li>
                <li><strong>SVM+HOG</strong>: Datasets grandes, m√°xima precisi√≥n requerida</li>
            </ul>
        </div>
    </div>

    <div class="section">
        <h2>üìÅ Archivos Generados</h2>
        <p>Durante el uso del sistema, se generan varios archivos:</p>

        <ul>
            <li><code>modelo_lbph.yml</code> - Modelo LBPH entrenado</li>
            <li><code>modelo_svm.pkl</code> - Modelo SVM entrenado</li>
            <li><code>label_encoder.pkl</code> - Codificador de etiquetas</li>
            <li><code>personas.pkl</code> - Lista de nombres de personas</li>
            <li><code>rostros_extraidos_inferidos/</code> - Carpeta con rostros extra√≠dos durante el reconocimiento</li>
        </ul>
    </div>

    <div class="section">
        <h2>üîß Soluci√≥n de Problemas</h2>

        <h3>Error: "No se encontraron modelos entrenados"</h3>
        <p><strong>Soluci√≥n:</strong> Ejecuta primero la opci√≥n 1 para entrenar el sistema.</p>

        <h3>Error: "No se encontraron rostros en el dataset"</h3>
        <p><strong>Soluci√≥n:</strong> Verifica que las im√°genes contengan rostros visibles y bien iluminados.</p>

        <h3>Pocos reconocimientos o muchos falsos positivos</h3>
        <p><strong>Soluci√≥n:</strong> Ajusta los umbrales en la opci√≥n 4, o agrega m√°s fotos al dataset.</p>
    </div>

    <div class="section">
        <h2>üìú C√≥digo Completo del Script</h2>
        <p>A continuaci√≥n se muestra el c√≥digo completo del sistema de reconocimiento facial:</p>

        <div class="code-container">
            <code>
'''


Caracter√≠sticas principales:

Dos algoritmos de reconocimiento:

LBPH (Local Binary Pattern Histograms): R√°pido y eficiente
SVM con caracter√≠sticas HOG: M√°s preciso para datasets grandes


Funcionalidades:

Entrenamiento autom√°tico desde carpetas organizadas
Detecci√≥n y reconocimiento en im√°genes est√°ticas
Reconocimiento en tiempo real con webcam
Interfaz de men√∫ f√°cil de usar
Extracci√≥n autom√°tica de rostros reconocidos a archivos con nombre del identificado
Redimensionamiento autom√°tico de im√°genes grandes (m√°ximo 512px ancho) para mejor visualizaci√≥n


Estructura del dataset:
rostros_dataset/
‚îú‚îÄ‚îÄ persona1/
‚îÇ   ‚îú‚îÄ‚îÄ foto1.jpg
‚îÇ   ‚îî‚îÄ‚îÄ foto2.jpg
‚îú‚îÄ‚îÄ persona2/
‚îÇ   ‚îú‚îÄ‚îÄ foto1.jpg
‚îÇ   ‚îî‚îÄ‚îÄ foto2.jpg
‚îî‚îÄ‚îÄ ...


Dependencias necesarias:

pip install opencv-python opencv-contrib-python scikit-learn numpy joblib
C√≥mo usar:

Preparar dataset: Crea carpetas con nombres de personas y coloca sus fotos dentro
Entrenar: Ejecuta el script y selecciona la opci√≥n 1
Reconocer: Usa las opciones 2 o 3 para reconocimiento en im√°genes o tiempo real

El sistema guarda autom√°ticamente los modelos entrenados y puede reconocer rostros con m√©tricas de confianza


'''



import cv2
import numpy as np
import os
import pickle
import time
from sklearn.svm import SVC
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import joblib

class FaceRecognitionTrainer:
    def __init__(self, dataset_path="rostros_dataset"):
        self.dataset_path = dataset_path
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.recognizer = cv2.face.LBPHFaceRecognizer_create()
        self.label_encoder = LabelEncoder()
        self.svm_model = SVC(kernel='rbf', probability=True, random_state=42)

    def create_dataset_structure(self):
        """Crea la estructura de carpetas para el dataset"""
        if not os.path.exists(self.dataset_path):
            os.makedirs(self.dataset_path)
            print(f"Carpeta {self.dataset_path} creada.")
            print("Por favor, crea subcarpetas con los nombres de las personas")
            print("y coloca las im√°genes de cada persona en su respectiva carpeta.")

    def extract_faces_from_image(self, image_path, target_size=(100, 100)):
        """Extrae rostros de una imagen"""
        image = cv2.imread(image_path)
        if image is None:
            return []

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.1,
            minNeighbors=5,
            minSize=(30, 30)
        )

        face_images = []
        for (x, y, w, h) in faces:
            face = gray[y:y+h, x:x+w]
            face_resized = cv2.resize(face, target_size)
            face_images.append(face_resized)

        return face_images

    def load_training_data(self):
        """Carga las im√°genes de entrenamiento desde el dataset"""
        faces = []
        labels = []
        person_names = []

        print("Cargando im√°genes de entrenamiento...")

        for person_name in os.listdir(self.dataset_path):
            person_path = os.path.join(self.dataset_path, person_name)
            if not os.path.isdir(person_path):
                continue

            person_names.append(person_name)
            print(f"Procesando im√°genes de: {person_name}")

            for image_name in os.listdir(person_path):
                if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_path = os.path.join(person_path, image_name)
                    face_images = self.extract_faces_from_image(image_path)

                    for face in face_images:
                        faces.append(face)
                        labels.append(person_name)

        if len(faces) == 0:
            raise ValueError("No se encontraron rostros en el dataset")

        print(f"Se cargaron {len(faces)} rostros de {len(set(labels))} personas")
        return faces, labels, person_names

    def train_lbph_model(self, faces, labels):
        """Entrena el modelo LBPH (Local Binary Pattern Histograms)"""
        print("Entrenando modelo LBPH...")

        # Codificar labels
        encoded_labels = self.label_encoder.fit_transform(labels)

        # Entrenar el reconocedor LBPH
        self.recognizer.train(faces, np.array(encoded_labels))

        print("Modelo LBPH entrenado exitosamente")

    def train_svm_model(self, faces, labels):
        """Entrena un modelo SVM usando caracter√≠sticas HOG"""
        print("Entrenando modelo SVM con caracter√≠sticas HOG...")

        # Extraer caracter√≠sticas HOG
        hog = cv2.HOGDescriptor()
        features = []

        for face in faces:
            # Redimensionar para HOG
            face_resized = cv2.resize(face, (64, 128))
            hog_features = hog.compute(face_resized)
            features.append(hog_features.flatten())

        features = np.array(features)
        encoded_labels = self.label_encoder.fit_transform(labels)

        # Dividir datos en entrenamiento y prueba
        X_train, X_test, y_train, y_test = train_test_split(
            features, encoded_labels, test_size=0.2, random_state=42
        )

        # Entrenar SVM
        self.svm_model.fit(X_train, y_train)

        # Evaluar modelo
        y_pred = self.svm_model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"Precisi√≥n del modelo SVM: {accuracy:.2f}")

    def save_models(self):
        """Guarda los modelos entrenados"""
        print("Guardando modelos...")

        # Guardar modelo LBPH
        self.recognizer.save('modelo_lbph.yml')

        # Guardar modelo SVM y encoder
        joblib.dump(self.svm_model, 'modelo_svm.pkl')
        joblib.dump(self.label_encoder, 'label_encoder.pkl')

        # Guardar nombres de personas
        with open('personas.pkl', 'wb') as f:
            pickle.dump(self.label_encoder.classes_, f)

        print("Modelos guardados exitosamente")

    def train_complete_system(self):
        """Entrena el sistema completo de reconocimiento facial"""
        try:
            # Crear estructura de dataset
            self.create_dataset_structure()

            # Verificar que existan im√°genes
            if not any(os.path.isdir(os.path.join(self.dataset_path, item))
                      for item in os.listdir(self.dataset_path)):
                print("‚ö†Ô∏è  No se encontraron carpetas de personas en el dataset.")
                print("Crea carpetas con nombres de personas y coloca sus im√°genes dentro.")
                return False

            # Cargar datos de entrenamiento
            faces, labels, person_names = self.load_training_data()

            # Entrenar ambos modelos
            self.train_lbph_model(faces, labels)
            self.train_svm_model(faces, labels)

            # Guardar modelos
            self.save_models()

            print("\n‚úÖ Entrenamiento completado exitosamente!")
            print(f"üìä Resumen:")
            print(f"   - Personas entrenadas: {len(person_names)}")
            print(f"   - Total de rostros: {len(faces)}")
            print(f"   - Modelos guardados: LBPH y SVM")

            return True

        except Exception as e:
            print(f"‚ùå Error durante el entrenamiento: {str(e)}")
            return False

class FaceRecognizer:
    def __init__(self):
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        # Ajustes para reducir falsos positivos
        self.MIN_FACE_SIZE = 50  # Tama√±o m√≠nimo del rostro en p√≠xeles
        self.LBPH_CONFIDENCE_THRESHOLD = 80  # Umbral de confianza para LBPH (menor = m√°s estricto)
        self.SVM_PROBABILITY_THRESHOLD = 0.6  # Umbral de probabilidad para SVM (mayor = m√°s estricto)
        # Par√°metros m√°s estrictos para detecci√≥n facial
        self.DETECTION_SCALE_FACTOR = 1.2  # Mayor escala = menos falsos positivos
        self.DETECTION_MIN_NEIGHBORS = 8  # Mayor vecino m√≠nimo = m√°s estricto
        self.load_models()

    def load_models(self):
        """Carga los modelos entrenados"""
        try:
            # Cargar modelo LBPH
            self.recognizer = cv2.face.LBPHFaceRecognizer_create()
            self.recognizer.read('modelo_lbph.yml')

            # Cargar modelo SVM y encoder
            self.svm_model = joblib.load('modelo_svm.pkl')
            self.label_encoder = joblib.load('label_encoder.pkl')

            # Cargar nombres de personas
            with open('personas.pkl', 'rb') as f:
                self.person_names = pickle.load(f)

            print("Modelos cargados exitosamente")

        except FileNotFoundError:
            print("‚ùå No se encontraron modelos entrenados. Ejecuta primero el entrenamiento.")

    def recognize_faces_in_image(self, image_path, method='lbph'):
        """Reconoce rostros en una imagen con par√°metros optimizados para reducir falsos positivos"""
        image = cv2.imread(image_path)
        if image is None:
            print("No se pudo cargar la imagen")
            return None

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(
            gray,
            scaleFactor=self.DETECTION_SCALE_FACTOR,
            minNeighbors=self.DETECTION_MIN_NEIGHBORS,
            minSize=(self.MIN_FACE_SIZE, self.MIN_FACE_SIZE)
        )

        # Crear directorio para rostros extra√≠dos si no existe
        output_dir = "rostros_extraidos_inferidos"
        os.makedirs(output_dir, exist_ok=True)

        recognized_faces = 0
        face_counter = {}  # Contador para cada persona

        for (x, y, w, h) in faces:
            # Verificar tama√±o m√≠nimo del rostro
            if w < self.MIN_FACE_SIZE or h < self.MIN_FACE_SIZE:
                continue

            face = gray[y:y+h, x:x+w]

            if method == 'lbph':
                # Usar modelo LBPH con control de confianza
                face_resized = cv2.resize(face, (100, 100))
                label, confidence = self.recognizer.predict(face_resized)

                # Rechazar si confianza es baja (valores altos indican baja confianza en LBPH)
                if confidence > self.LBPH_CONFIDENCE_THRESHOLD:
                    continue

                person_name = self.label_encoder.inverse_transform([label])[0]
                confidence_text = f"{confidence:.1f}"

            elif method == 'svm':
                # Usar modelo SVM con control de probabilidad
                face_resized = cv2.resize(face, (64, 128))
                hog = cv2.HOGDescriptor()
                features = hog.compute(face_resized).flatten().reshape(1, -1)

                prediction = self.svm_model.predict(features)[0]
                person_name = self.label_encoder.inverse_transform([prediction])[0]
                probability = self.svm_model.predict_proba(features)[0].max()

                # Rechazar si probabilidad es baja
                if probability < self.SVM_PROBABILITY_THRESHOLD:
                    continue

                confidence_text = f"{probability:.2f}"

            # Inicializar contador para nueva persona
            if person_name not in face_counter:
                face_counter[person_name] = 0

            face_counter[person_name] += 1

            # Extraer rostro de la imagen original (imagen a color)
            face_color = image[y:y+h, x:x+w]

            # Crear nombre de archivo con nombre del reconocido, contador y timestamp
            timestamp = int(time.time())
            filename = f"{person_name}_{face_counter[person_name]}_{timestamp}.jpg"
            output_path = os.path.join(output_dir, filename)

            # Guardar el rostro extra√≠do
            cv2.imwrite(output_path, face_color)
            print(f"‚úì Rostro guardado: {output_path}")

            # Dibujar rect√°ngulo y nombre
            cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.putText(image, f"{person_name} ({confidence_text}) - Guardado",
                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            recognized_faces += 1

        print(f"Se reconocieron {recognized_faces} rostros v√°lidos en la imagen")
        if recognized_faces > 0:
            print(f"üíæ Rostros extra√≠dos guardados en carpeta '{output_dir}'")

        # Redimensionar la imagen para visualizaci√≥n si es muy grande
        display_image = image.copy()
        height, width = display_image.shape[:2]

        # Limitar ancho m√°ximo a 512 p√≠xeles manteniendo relaci√≥n de aspecto
        max_width = 512
        if width > max_width:
            ratio = max_width / width
            new_width = int(width * ratio)
            new_height = int(height * ratio)
            display_image = cv2.resize(display_image, (new_width, new_height))
            print(f"Imagen redimensionada para visualizaci√≥n: {new_width}x{new_height}")

        return display_image

    def recognize_from_webcam(self, method='lbph'):
        """Reconocimiento en tiempo real desde la webcam con par√°metros optimizados para reducir falsos positivos"""
        cap = cv2.VideoCapture(0)

        print("Presiona 'q' para salir")
        print("Algoritmo:", method.upper())
        print("Par√°metros anti-falsos-positivos activados")
        print("Presiona 's' para guardar rostros reconocidos manualmente")

        # Crear directorio para rostros extra√≠dos si no existe
        output_dir = "rostros_extraidos_inferidos"
        os.makedirs(output_dir, exist_ok=True)

        recognized_faces = 0
        face_counter = {}  # Contador para cada persona
        last_save_time = 0  # Para controlar frecuencia de guardado autom√°tico

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # Usar par√°metros estrictos para detecci√≥n
            faces = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=self.DETECTION_SCALE_FACTOR,
                minNeighbors=self.DETECTION_MIN_NEIGHBORS,
                minSize=(self.MIN_FACE_SIZE, self.MIN_FACE_SIZE)
            )

            current_recognized = 0
            for (x, y, w, h) in faces:
                # Verificar tama√±o m√≠nimo adicional
                if w < self.MIN_FACE_SIZE or h < self.MIN_FACE_SIZE:
                    continue

                face = gray[y:y+h, x:x+w]

                if method == 'lbph':
                    # Usar modelo LBPH con control de confianza
                    face_resized = cv2.resize(face, (100, 100))
                    label, confidence = self.recognizer.predict(face_resized)

                    # Rechazar si confianza es baja
                    if confidence > self.LBPH_CONFIDENCE_THRESHOLD:
                        # Dibujar rect√°ngulo rojo para rostro detectado pero no reconocido
                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)
                        cv2.putText(frame, f"Desconocido ({confidence:.1f})",
                                   (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                        continue

                    person_name = self.label_encoder.inverse_transform([label])[0]
                    confidence_text = f"{confidence:.1f}"

                elif method == 'svm':
                    # Usar modelo SVM con control de probabilidad
                    face_resized = cv2.resize(face, (64, 128))
                    hog = cv2.HOGDescriptor()
                    features = hog.compute(face_resized).flatten().reshape(1, -1)

                    prediction = self.svm_model.predict(features)[0]
                    person_name = self.label_encoder.inverse_transform([prediction])[0]
                    probability = self.svm_model.predict_proba(features)[0].max()

                    # Rechazar si probabilidad es baja
                    if probability < self.SVM_PROBABILITY_THRESHOLD:
                        # Dibujar rect√°ngulo rojo para rostro detectado pero no reconocido
                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)
                        cv2.putText(frame, f"Desconocido ({probability:.2f})",
                                   (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                        continue

                    confidence_text = f"{probability:.2f}"

                # Inicializar contador para nueva persona si no existe
                if person_name not in face_counter:
                    face_counter[person_name] = 0

                # Dibujar rect√°ngulo verde y nombre para reconocimiento exitoso
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                cv2.putText(frame, f"{person_name} ({confidence_text})",
                           (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                current_recognized += 1
                recognized_faces += 1

                # Preparar extracci√≥n (solo si se presiona 's' o autom√°ticamente cada 30 segundos)
                current_time = time.time()
                if current_time - last_save_time > 30:  # Guardado autom√°tico cada 30 segundos
                    face_counter[person_name] += 1
                    # Extraer rostro de la imagen original (imagen a color)
                    face_color = frame[y:y+h, x:x+w]

                    # Crear nombre de archivo con nombre del reconocido, contador y timestamp
                    timestamp = int(current_time)
                    filename = f"{person_name}_webcam_{face_counter[person_name]}_{timestamp}.jpg"
                    output_path = os.path.join(output_dir, filename)

                    # Guardar el rostro extra√≠do
                    cv2.imwrite(output_path, face_color)
                    print(f"\n‚úì Rostro guardado: {output_path}")
                    last_save_time = current_time

            cv2.imshow('Reconocimiento Facial', frame)
            print(f"\rRostros reconocidos en este frame: {current_recognized}", end='', flush=True)

            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                # Guardado manual por cada rostro reconocido
                for person_name in list(face_counter.keys())[:current_recognized]:  # Guardar solo rostros actuales
                    faces_in_frame = self.face_cascade.detectMultiScale(
                        cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY),
                        scaleFactor=self.DETECTION_SCALE_FACTOR,
                        minNeighbors=self.DETECTION_MIN_NEIGHBORS,
                        minSize=(self.MIN_FACE_SIZE, self.MIN_FACE_SIZE)
                    )

                    for i, (x, y, w, h) in enumerate(faces_in_frame):
                        if i >= current_recognized:  # Solo rostros reconocidos en este frame
                            break
                        face_color = frame[y:y+h, x:x+w]
                        face_counter[person_name] += 1
                        timestamp = int(time.time())
                        filename = f"{person_name}_manual_{face_counter[person_name]}_{timestamp}.jpg"
                        output_path = os.path.join(output_dir, filename)
                        cv2.imwrite(output_path, face_color)
                        print(f"\n‚úì Rostro guardado manualmente: {output_path}")
                last_save_time = time.time()

        print("\n")
        if recognized_faces > 0:
            print(f"üíæ Rostros extra√≠dos guardados en carpeta '{output_dir}'")
        cap.release()
        cv2.destroyAllWindows()

def main():
    print("ü§ñ Sistema de Reconocimiento Facial")
    print("=" * 40)
    print("‚ú® MEJORADO: Par√°metros optimizados para reducir falsos positivos")
    print("   - Umbrales de confianza estrictos")
    print("   - Detecci√≥n facial m√°s precisa")
    print("   - Rechazo autom√°tico de detecciones poco confiables")

    while True:
        print("\nOpciones:")
        print("1. Entrenar modelos")
        print("2. Reconocer rostros en imagen")
        print("3. Reconocimiento en tiempo real (webcam)")
        print("4. Configurar umbrales")
        print("5. Salir")

        choice = input("\nSelecciona una opci√≥n: ")

        if choice == '1':
            trainer = FaceRecognitionTrainer()
            trainer.train_complete_system()

        elif choice == '2':
            recognizer = FaceRecognizer()
            image_path = input("Ingresa la ruta de la imagen: ")
            method = input("M√©todo (lbph/svm) [lbph]: ").lower() or 'lbph'

            result = recognizer.recognize_faces_in_image(image_path, method)
            if result is not None:
                cv2.imshow('Resultado', result)
                print("Presiona cualquier tecla para continuar...")
                cv2.waitKey(0)
                cv2.destroyAllWindows()

        elif choice == '3':
            recognizer = FaceRecognizer()
            method = input("M√©todo (lbph/svm) [lbph]: ").lower() or 'lbph'
            recognizer.recognize_from_webcam(method)

        elif choice == '4':
            # Crear un reconocedor temporal para mostrar configuraci√≥n
            temp_recognizer = FaceRecognizer()

            print("\n‚öôÔ∏è  Configuraci√≥n actual de par√°metros anti-falsos-positivos:")
            print(f"   - Tama√±o m√≠nimo del rostro: {temp_recognizer.MIN_FACE_SIZE} p√≠xeles")
            print(f"   - Umbral de confianza LBPH: {temp_recognizer.LBPH_CONFIDENCE_THRESHOLD}")
            print(f"   - Umbral de probabilidad SVM: {temp_recognizer.SVM_PROBABILITY_THRESHOLD}")
            print(f"   - Factor de escala de detecci√≥n: {temp_recognizer.DETECTION_SCALE_FACTOR}")
            print(f"   - Vecinos m√≠nimos de detecci√≥n: {temp_recognizer.DETECTION_MIN_NEIGHBORS}")

            print("\nüí° Recomendaciones:")
            print("   - Para m√°s precisi√≥n: Aumentar los umbrales")
            print("   - Para m√°s detecciones: Reducir los umbrales")
            print("   - Valores bajos de LBPH indican mejor confianza")
            print("   - Valores altos de SVM indican mejor confianza")
            print("\nüìù Nota: Estos par√°metros est√°n optimizados para reducir falsos positivos")
            print("     Considera ajustar si tienes muchos falsos negativos")

        elif choice == '5':
            print("¬°Hasta luego!")
            break

        else:
            print("Opci√≥n no v√°lida")

if __name__ == "__main__":
    main()
            </code>
        </div>
    </div>

    <div class="section">
        <h2>üéØ Conclusi√≥n</h2>
        <p>Este sistema de reconocimiento facial ofrece una soluci√≥n completa y avanzada para identificar personas mediante algoritmos de machine learning. Con su interfaz f√°cil de usar y capacidades tanto para an√°lisis de im√°genes est√°ticas como en tiempo real, resulta ideal para una variedad de aplicaciones pr√°ctica.</p>

        <div class="highlight">
            <strong>Pr√≥ximos pasos sugeridos:</strong>
            <ul>
                <li>Expandir el dataset para mejorar la precisi√≥n</li>
                <li>Implementar reconocimiento en video streams</li>
                <li>A√±adir m√©tricas de evaluaci√≥n m√°s detalladas</li>
                <li>Integrar con otros sistemas o APIs</li>
            </ul>
        </div>
    </div>

    <footer style="text-align: center; margin-top: 40px; color: #666;">
        <p><a href="pildoras.html">Volver a P√≠ldoras</a></p>
        <p>Tutorial creado para el script <strong>1-reconocimento_facial.py</strong></p>
        <p>Desarrollado con Python, OpenCV y scikit-learn</p>
    </footer>
</body>
</html>
